# 11. Week - 9 December 2024 Monday

# Sınav Soruları
Soruların üzerinden geçiyoruz. Hepsine bakmadık. Hızlıca gözden geçirdik.  
TODO: Bu sorulardan finalde tekrar soru gelebilir.

## 1. Soru
c) artar veya değişmez

## 2. Soru
a) Yanlış. Her zaman engellemez
b) Şehir, renk gibi şeyler. Distance based bir yöntem olduğu için kullanamayız. 
c) Yanlış. İmbalanced verilerde yanlış.
d) Yanlış. Bağımsız olmalarına dayanır.

## 3. Soru
Hata 0 olur. Karar sınırı değişmeyeceğinden LOOCV sonucu değiştirmez.

# Feature Selection
Mevcut özelliklerinden hangisini seçeceğimizi belirlemek.

# Feature Extraction
Mevcut özelliklerle aynı olmayan yeni bir özellik çıkarımı yapılabiliyor.

## PCA: Principal Component Analysis 
TODO: Belki finalde bunun nasıl hesaplandığı ile alakalı soru sorabilir.

* Daha çok sinyal işlemede kullanılan bir yöntem.
* Bir ses sinyali tek boyutlu bir vektör. Burda neyi seçeceğimizi bilmediğimiz için özellikleri dönüştürerek aktarmak oldukça anlamlı hale geliyor.

Temel Özellikler:
* Ortalama hesaplanır.
* Varyans hesaplanır.
* Eigen value ve Eigen vektör hesapları yapılır.

## Yüz Tanıma

Test aşaması;
* y -> kim?
* ilk tüm feature ları traininde elde edilen mean lerden çıkar.
* Sonrasında eigen vektör ve value ları elde et.
* Sonrasında kim olduğuna karar vermek için aşağıdakilerden bir tanesini kullan.
  * Euclidean distance
  * K-NN
  * SVM

Yukarıdakileri uygulayan bir bitirme tezi:
* Viola - Jones
* https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework
* https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf

# Reinforcement Learning
* Bir önceki aldığınız kararın sonucuna göre bir sonraki kararı alıyorsunuz.
* Çok başarılı bir yöntem değildi. Fakat yapay zeka alanında olan son gelişmelerle birlikte (Deep Learning) tekrar popüler hale geldi. 

## Markov Decision Process (MDP)
* MDP: Markov Decision Process, reinforcement learning için kullanılan temel modeldir.
  * Her alacağım karar bir önceki kararın sonucuna bağlıdır şeklinde bir modeldir.
  * Her kararın sonuçlarından en iyi sonucu almak için bir strateji belirlenir.

* Agent: İşi yapan, karar veren, öğrenen, karar alan birimdir.
* Environment: Agent'ın kararlarından etkilenen ortam.
* State: Agent'ın bulunduğu durum.
* Action: Agent'ın yapabileceği hareketler.
* Reward: Agent'ın aldığı ödül.

# Ödev Açıklaması
* Bütün eğitmenli öğreticilerin performans analizinin yapılması ile alakalı bir ödev verilecek.
* Tüm gördüğümüz yöntemler verilen veri setine uygulanacak ve sonuçlar karşılaştırılacak.
* Veri setini hoca kendisi verecek
