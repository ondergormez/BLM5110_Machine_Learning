# 5. Week - 28 October 2024 Monday

Sınavda formül çok sormuyor.
* Ezberlememizi istemiyor
* Anlamamızı istiyor
* Örnek verip yorumlamamızı istiyor.

## Overfitting & Under Fitting

Underfitting occurs when a model is too simple.
* Daha çok modelinizle alakalı problemler var demektir.
* Veriyi temsil etmekte çok iyi değil.
* İterasyonu erken kesmiş olabilirsiniz (epoch).

## Model Selection
Her veri ve durum için en iyi sonucu veren bir model yoktur. Veriye ve context e göre hangi makine öğrenmesi modelini (desicion tree, linear regression, SVP, KNN, Naive Bayes, K-Means, ...) seçeceğimize biz karar vermeliyiz.
* **Literatür Taraması**: Buna benzer sorunlar/konular için hangi modeller seçilmiş? Ne kadar başarı elde edilmiş?
* **Model Selection**: İki tane aynı sonucu veren modeliniz varsa, basit olanı seçin.
* **Feature Selection**: Modeli tasarlarken seçtiğiniz özellikler başarıyı çok etkiler. Hangi özellikleri dışarda bırakacaksınız?
* **Parametre Seçimi**: Learning Rate, k değeri gibi çeşitli parametrelerin değerlerinin değişmesi modelin başarısını çok etkiler.

## Fine Tuning & Measurement Steps
Aynı anda birden fazla şeyi değiştirmeyin. Böyle yaparsanız hangisinden kaynaklı başarının değiştiğini gözlemleyemezsiniz.
* Özellikleri değiştirin, parametreleriniz aynı kalsın. Başarı ölçün.
* Parametreleri değiştirin, özellikleriniz aynı kalsın.
* Veri setini değiştirdiyseniz, başka bir şeyi değiştirmeden denemelerinizi yapın.
* Her yaptığınız denemeyi kaydedin. Çünkü başarısız sonuçlar elde etmiş olmak da bilimsel araştırmada bir sonuçtur. Ayrıca hangi yöntemlerin başarısız olduğunu ilerde hatırlamaz ve tekrar denersiniz. Bunun önüne geçmek içinde denemelerinizi kaydedin.

# Train Test Splitting

## 1) Holdout Method

Şu anda çok sık kullanılan bir yöntemdir. Örnek sayısı çoksa direkt bu kullanılabilir.

* %70 training için, %30 testing için ayrılır.
* **Stratified Sample**: Advanced version of balancing the data
  * Make sure that each class is represented with approximately equal proportions in both subsets
  * TODO: Fraud detection gibi nadir karşılaşılan veri için kullanacağımız veri setinde train ve test için bölüyorsam fraud olanların %70'i training %30'u test setinde bulunmalıdır. Random seçilmeli fakat data bölünmeden önceki sınıf oranları korunmalıdır.

Nadir veriler için;
* **Data Augmentation**: Gerçekten çok gerçeğe benzer fakat gerçek olmayan datalar üretilerek nadir görülen sınıfın sample sayısı arttırılabilir.
* **Percentage Changing**: Fraud olmayan datalar %90 ve fraud %10 ise
  * Yavaş yavaş data oranlarını değiştirin. 
  * %80 normal ve %20 fraud denenebilir.
  * %60 normal ve %40 fraud gibi. 
  * Bunu yaparken normal olanların sayısını azaltıyoruz. Çünkü elimizde daha fazla fraud olan veri yok.

## 2) Random Subsampling

Örnek sayısının az olduğu durumlarda kullanılan yöntemdir.

Her deneyi yaparken random olarak test setini belirliyoruz. Böylelikle modelin daha doğru çalışmasını sağlayabiliriz.
* Bu şekilde n tane test yapıyoruz.
* Hatayı her testing sonucundaki hatanın ortalaması olarak alıyoruz.

## 3) K-Fold Cross Validation
Örnek sayısının az olduğu durumlarda kullanılan yöntemdir.

* Ayrı bir test datası kullanılmasına gerek kalmıyor.
* Bütün örneklerin hem test hemde trainde kullanılacağı bir yöntemdir.
* k değerini biz seçiyoruz. Örneğin 5.
* Ex1: Train, Train, Train, Train, Test
* Ex2: Train, Test, Train, Train, Train
* ...
* gibi 5 farklı yerden test sample ı seçiliyor.

* Leave one out Cross Validation
  * N - 1 örneğimiz train için, 1 tanesi test için kullanılıyor.
  * Çok az data olduğu zaman (Örn: 50 sample) kullanılıyor.

## 4) Bootstrap
Randomly select N samples from dataset.

# Model Performance Evaluation

* Performansını nasıl ölçeceğiz? (Performans Evaluation)
* Çok temel performans ölçme teknikleri var (Precision, Recall, Accuracy, F1-score, etc.)
* TODO: Literatürde benzer problemler için hangi metrik kullanılmış ona bir bakın. Buna göre daha rahat karar verebilirsiniz.

## 1) Confusion Matrix
Mutlaka çalışmalarınızda confusion matrix kullanın. Çünkü bu matrix size modelinizin ne kadar başarılı olduğunu gösterir.

![](https://cdn.prod.website-files.com/660ef16a9e0687d9cc27474a/662c42677529a0f4e97e4f96_644aea65cefe35380f198a5a_class_guide_cm08.png)

Image Source: https://cdn.prod.website-files.com/660ef16a9e0687d9cc27474a/662c42677529a0f4e97e4f96_644aea65cefe35380f198a5a_class_guide_cm08.png

* TP: True Positive
* TN: True Negative
* FP: False Positive
* FN: False Negative

Veriye göre hangi oranın azaltılması gerektiği değişebiliyor.

Positive: İlgilendiğimiz durum.
* Mail spam tespitinde spam olanlar pozitif.
  * False positif: Mail spam değilken spam olarak işaretlenmesi mailin kaybedilmesine neden olur. Bunun azaltılması lazım.
* Hastalık tespitinde hasta olunan durum pozitif. 
  * Covid pozitif çıkması mesela.
  * False negative: Hastayken (kanser) hasta değil demek çok büyük bir problem. Bunun azaltılması gerekiyor.



## 2) Accuracy
Single Number Evaluation Metric:
* Accuracy: (TP + TN) / (TP + TN + FP + FN)

Önemli Not: Accuracy nadir görülen durumlarda (fraud ile normal işlem) çok yüksek çıkmasına rağmen gerçekten modelin başarısı hakkında bilgi vermez.
* Çünkü nadir durumlar çok az olduğu için modelin başarısı hakkında yanıltıcı olabilir.
* Fraud detection gibi nadir durumlar için accuracy kullanılmamalıdır.
* Imbalanced (unbalanced) data setlerde accuracy kullanılmamalıdır.

## 3) Precision
Pozitif olarak tahmin ettiklerinin içerisinde % kaçı positifti gerçekten? Bunu tahmin etmek için kullanılır.
* Precision: TP / (TP + FP)

## 4) Recall
Gerçekten pozitif olanların % kaçını doğru olarak tahmin ettik? Bunu tahmin etmek için kullanılır.
* Recall: TP / (TP + FN)

## 5) F1-Score
Ayrı ayrı precision ve recall değerlerini kullanmak yerine F1-score kullanılabilir.
* Modelin genel başarısı hakkında bize bilgi verir.
* F1-Score: 2 * (Precision * Recall) / (Precision + Recall)

# Logistic Regression
Konu değiştiriyoruz.

* Bir sınıflandırma yöntemi.
* Regresyon yöntemi değil. Adından yanlış anlamayalım.
* Binary classification metodu
* Sigmoid fonksiyonu kullanılıyor.

* Verilen giriş değerleri için bilinmeyen örneğin hangi sınıfa ait olduğunun **olasılığını** verir.
* Genellikle **iki sınıflı** verileri sınıflandırmak için kullanılır.

Online Logistic Regression Algoritması;
* Hatanın her adımda düzeltilmesi demek
* Initialize weights [-0.5, 0.5]
* repeat
  * next data point
  * update weights according to error
  * end
  * until covergance

Logistic regression içinde gradient descent kullanılıyor. Türev alıyoruz.

* 2 sınıfımız varsa bize bir olasılık sonucu verecek. Bu olasılığa bakarak hangi sınıfa ait olduğuna karar vereceğiz
* 2 den fazla sınıfımız varsa multinominal logistic regression oluyor.
  * Softmax(Zi) yöntemi kullanılır. Her sınıfın ayrı ayrı olasılığını veriyor.
  * Her örneğin bulunma olasılığını hesaplıyor.
  * Toplam olasılık 1 oluyor.
  * Softmax sonucu en büyük olasılık değerini alan sınıf, verinin gerçek sınıfıdır şeklinde yorumluyoruz.
