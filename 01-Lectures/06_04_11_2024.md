# 6. Week - 4 November 2024 Monday

# ANN: Artificial Neural Networks
1958: Frank Rosenblatt introduces the Perceptron  
Perceptron: A single layer neural network

Eskiden paralel ve distributed computing yapılmaya çalışılıyordu.
* Yapay nöron ağları beynin paaralel ve distributed yapısını taklit etmeye çalışıyor.
* İnsan beyni 10 milyar nöron ve 60 trilyon sinaps içerir.

## Single Layer Perceptron / On-Line Learning (Stochastic Gradient Descent)
* Her seferinde ağırlıkları update ederek hatayı minimize etmeye yani azaltmaya çalışıyoruz
* TODO: Ödevde SGD ile w0 ağırlığını update etmek gerekebilecek bir kısım olacak.
* Tek bir doğru çizilerek yapılabilen sınıflandırmalar için kullanılır.

![](https://media.geeksforgeeks.org/wp-content/uploads/20221219111343/Single-Layer-Perceptron.png)

Image Source: https://media.geeksforgeeks.org/wp-content/uploads/20221219111343/Single-Layer-Perceptron.png

# Multi Layer Perceptron - Feed Forward Neural Network (FFNN)
* Geri besleme yok
* Birden fazla doğru çizerek ifade edilebilecek sınıflandırmalar için kullanılır.
* İçeride birden fazla hidden layer bulunur. Bu şekilde input a uygun çıkış verilebilir.
* Hata update edilirken en sondaki layer update edilir, sonra bir önceki, sonra bir önceki şeklinde devam eder.


![](https://aiml.com/wp-content/uploads/2022/06/Multilayer-perceptron-MLP.png)

Image Source: https://aiml.com/wp-content/uploads/2022/06/Multilayer-perceptron-MLP.png

TODO: Bu hafta işlenen FFNN konusuna ait mavi renkli slayt ın 39. sayfasında olan örneği çözdük. Bundan belki sınavda soru gelebilir.


# Batch Gradient Descent
* Yukarıdaki normal gradient descent ti.
* Batch olsaydı bütün örnekler için hata hesaplanıp sonra ağırlıklar güncellenecekti.

NOT: Mavi slayt üzerinden sayfa 50'ye kadar işledik.
