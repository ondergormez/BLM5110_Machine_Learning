# 4. Week - 21 October 2024 Monday


# Splitting Dataset
* Modelin başarısını ölçtükten sonra, (%83 çıktı) neden hata oluştu analizini yapmamız gerekiyor.

Veri setini 3 parçaya bölmeliyiz.
* Training data
* Validation (Development) data
* Test data

## Training Data
* Eğitim sırasında kullanılan datadır
* Başarım sonucunun en yüksek çıktığı yer burasıdır.

## Validation (Development) Data
* Sonucunu bildiğimiz duruma göre başarı oluşturmaktır.
* Sonucu bilerek işlemleri yapıyoruz.
* Ağacı budamak gerekiyorsa buduyoruz.
* Parametreleri değiştirmek gerekiyorsa değiştiriyoruz.
* Yani aslında ince ayar (fine tuning) işlemlerini burada yapıyoruz.

## Test Data
* Test seti başarısı o sistemin gerçek başarıdır.

* Test setin başarısı validation a yakın olursa modelimiz hazır diyebiliriz.
* Validation kısmında %80 başarı varken test setinde %60 gibi bir başarı elde ediliyorsa;
  * En başa geri dön. Training dataset ile tekrar eğit.
  * Validation ile validasyonunu yap.
  * Tekrar test datası ile sonuçları izle
  * Validation ve test birbirine yakın çıkana kadar devam et.

## Başarı Ölçümü

Başarı ölçümünde accuracy ve response time gibi parametreler kullanılır.

| Classifier | Accuracy | Running Time (ms) |
|------------|----------|-------------------|
|      A     |   0.90   |         80        |
|      B     |   0.92   |         95        |
|      C     |   0.95   |        1500       |


* Zaman kritik bir durumum yoksa en doğru sonucu ürettiği için C modelini seçerim.
* Eğer zaman kritik ise B'yi onun zamanı da çok geliyorsa A'yı seçerim.
* Sonuç olarak Accuracy kadar response time ında önemli olduğu uygulamalar olabilir. Çalışmalarda response time ıda göz önünde bulundurmak gerekebilir.
* Bir projeye başladığınızda, buna benzer projelerde performans ölçme metriği nedir diye bir bakın ve ona göre çalışmalarınızın performansını ölçüp karşılaştırın.

* Accuracy, precision, recall, hangisi kullanılacak?

Single Number Evaluation Metric: 

# Debugging the Learning Model
* Gather a sample of 100 dev set examples that the system misclassified and count what fraction of them are which class.
* Mutlaka ana senaryoları belirle ve çözümlerinin ne olacağı üzerine çalış.
* <span style="color:red;background-color: yellow; font-weight: bold; text-decoration: underline;">TODO: Genel bir sistemde konuya özel problemlerin sadece sık rastlananlarını belirle ve bunları çöz.</span>
* <span style="color:red;background-color: yellow; font-weight: bold; text-decoration: underline;">Az rastlanan problemi çözmeye çalışmak overfitting e neden olabilir.</span>
* Hataları katagorize etmeliyiz. Yöntemde bir şeyi değiştirirsem hatayı çözebilir miyim?
  * Kameranın yerini değiştirsem?
  * Tek kamera yerine 2 tane kamera kullansam?
* Cleaning up mislabeled examples
  * Sınıfları tanımlamayan fotoğrafları dataset ten çıkarmamız lazım. Örneğin lokasyon olarak yakınında bir yerde Lourve müzesi olarak etiketlenmiş örnek aslında müzeyi temsil etmemektedir. Bunu modelin doğru sınıflandırması mümkün değildir.
  * Etiketleme hatası çok sık rastlanan bir hatadır. Kime göre, neye göre bu şekilde etiketlenmiş?
  * Paper yazarken hakemlerde datanın kim tarafından etiketlendiğini sorar?
  * Genel bir dataysa kadın, erkek, yaşlar karışık şekillerde etiketletmek mantıklıdır.
  * Accuracy on dev set: 0.9
  * Errors due to mislabeled examples: 0.06
  * Errors due to other problems: 0.94

# Large Validation (Dev) Set
Validation sette modelde %20 hata varsa aşağıdakini uygula;
* Büyük bir kısmını otomatik etiketlet.
* Küçük bir kısmını manuel olarak sen etiketle

* If you have a large dev set, split into two subsets

5000 dev set samples
* 500 Eye ball -> Manually look at this
* 4500 -> blackbox 

# Basic Error Analysis

* Build and train a basic system as quickly as possible.
* 100 örnek alarak küçük bir sistem kurup başarıyı ölçümle.
  * Buradan direkt hangi case lerde hata var görülebilir.
  * Basit programlama hataları gibi durumları bulmak için faydalıdır. Çünkü program hızlıca çalışır ve sonuç üretir. Sonuçlarda hata varsa hatanın nerede olduğunu bulmak daha kolay olur.
  * Bu veriye dayalı bir sonraki adımda nasıl ilerlemen gerektiğine karar ver.

# Bias and Variance Trade Off

Bias: The error rate on the training set  
Variance: How much worse the algorithm does on the dev (or test) set than the training set.  

* Dev/Test set indeki performans training kümesindeki başarıdan küçüktür.
* Training set ile istediğiniz başarıya ulaşamıyorsanız training veri seti üzerinde algoritmanızı optimize etmeye çalışın.
* Training Er: 1%, Dev Error: %11 ise;
  * Bias: %1
  * Variance: %(11 - 1): %10: high variance
  * The classifier has very low training error, but it is failing to generalize to the dev set.
  * This is called **overfitting**.
  * Bias çok küçük ama variance çok büyük ise overfitting ile karşı karşıyayız demektir.
* If available bias is high, increase training dataset


# Proje

Kaggle web sitesine "dataset for classic machine learning" yazarak verisetini bulabilirsiniz.

* Yarışmalarda yapılanları tekrarlamayı deneyin
* Şu basit şeyleri yapın fakat bunlarla yetinmeyin tabi
  * batch size ını 500 den 1500 e kadar değiştirdim.
  * parametreyi 0.1 den 1 e kadar değiştirdim.
  * learning rate i 0.1 den 1 e kadar değiştirdim.
  * Veri setiniz büyükse hepsini kullanmadan temel hataları çözün. Sonra tüm veriseti üzerinde çalışın ki süreç hızlansın.

100 özellik vardı. Bunlardan
* İnternetten 10 farklı yazarın 30 günlük yazılarını topladım. Yazarı tanıdım gibi bir şeyde yapabilirsiniz.
* İlk seferde seçtiğimiz konuyu beğenmezse bir hak daha verecek.
* Fishing detection için bir veriseti oluşturulabilir belki.
